import streamlit as st
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
import tensorflow as tf
import io
from PIL import Image
import os

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="Nh·∫≠n D·∫°ng K√Ω T·ª± Vi·∫øt Tay",
    page_icon="üî§",
    layout="wide"
)

# Cache model ƒë·ªÉ tr√°nh load l·∫°i m·ªói l·∫ßn
@st.cache_resource
def load_ocr_model():
    """Load m√¥ h√¨nh OCR ƒë√£ ƒë∆∞·ª£c train"""
    try:
        model = load_model('my_modelcnn.h5')
        return model
    except Exception as e:
        st.error(f"Kh√¥ng th·ªÉ load model: {e}")
        return None

def preprocess_char(img):
    """Ti·ªÅn x·ª≠ l√Ω ·∫£nh k√Ω t·ª± ƒë·ªÉ ph√π h·ª£p v·ªõi ƒë·ªãnh d·∫°ng EMNIST"""
    # Chuy·ªÉn v·ªÅ grayscale n·∫øu c·∫ßn
    if len(img.shape) > 2:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # ƒê·∫£o ng∆∞·ª£c n·∫øu c·∫ßn (EMNIST c√≥ ch·ªØ tr·∫Øng tr√™n n·ªÅn ƒëen)
    if np.mean(img) > 127:
        img = 255 - img
    
    # √Åp d·ª•ng Otsu's thresholding
    _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    # T√¨m center of mass
    m = cv2.moments(img)
    if m["m00"] != 0:
        cx = int(m["m10"] / m["m00"])
        cy = int(m["m01"] / m["m00"])
    else:
        cx, cy = img.shape[1] // 2, img.shape[0] // 2
    
    # L·∫•y bounding box
    contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if contours:
        x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))
        # C·∫Øt theo bounding box v·ªõi m·ªôt ch√∫t margin
        margin = 4
        x_min = max(0, x - margin)
        y_min = max(0, y - margin)
        x_max = min(img.shape[1], x + w + margin)
        y_max = min(img.shape[0], y + h + margin)
        img = img[y_min:y_max, x_min:x_max]
    
    # Resize v·ªÅ 20x20 v√† pad v·ªÅ 28x28 (chu·∫©n EMNIST)
    if img.size > 0:
        # Resize v·ªÅ 20x20 gi·ªØ t·ª∑ l·ªá khung h√¨nh
        h, w = img.shape
        if h > w:
            new_h, new_w = 20, int(w * 20 / h)
        else:
            new_h, new_w = int(h * 20 / w), 20
        
        if new_h > 0 and new_w > 0:
            img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
            
        # Pad v·ªÅ 28x28
        h, w = img.shape
        top = (28 - h) // 2
        bottom = 28 - h - top
        left = (28 - w) // 2
        right = 28 - w - left
        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)
    else:
        img = np.zeros((28, 28), dtype=np.uint8)
    
    return img

def segment_characters(img):
    """Ph√¢n ƒëo·∫°n k√Ω t·ª± t·ª´ ·∫£nh c√≥ nhi·ªÅu k√Ω t·ª± vi·∫øt tay"""
    # Chuy·ªÉn v·ªÅ grayscale n·∫øu c·∫ßn
    if len(img.shape) > 2:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray = img.copy()
    
    # √Åp d·ª•ng thresholding
    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    
    # T√¨m contours
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # S·∫Øp x·∫øp contours t·ª´ tr√°i qua ph·∫£i
    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[0])
    
    char_images = []
    bounding_boxes = []
    
    for contour in contours:
        # L·∫•y bounding box
        x, y, w, h = cv2.boundingRect(contour)
        
        # L·ªçc b·ªè contours qu√° nh·ªè (nhi·ªÖu)
        if w > 5 and h > 5:
            # Tr√≠ch xu·∫•t k√Ω t·ª±
            char_img = thresh[y:y+h, x:x+w]
            # Ti·ªÅn x·ª≠ l√Ω k√Ω t·ª±
            processed_char = preprocess_char(char_img)
            char_images.append(processed_char)
            bounding_boxes.append((x, y, w, h))
    
    return char_images, bounding_boxes

def recognize_text(model, char_images):
    """Nh·∫≠n d·∫°ng k√Ω t·ª± v√† k·∫øt h·ª£p th√†nh text"""
    # Map indices th√†nh letters (A-Z)
    letters = [chr(i + ord('A')) for i in range(26)]
    
    recognized_text = ""
    confidence_scores = []
    
    for char_img in char_images:
        # Chu·∫©n h√≥a v√† reshape cho model input
        img = char_img.reshape(1, 28, 28, 1).astype('float32') / 255.0
        
        # D·ª± ƒëo√°n
        prediction = model.predict(img, verbose=0)
        predicted_class = np.argmax(prediction)
        confidence = np.max(prediction)
        
        # Chuy·ªÉn th√†nh k√Ω t·ª±
        if predicted_class < len(letters):
            recognized_text += letters[predicted_class]
            confidence_scores.append(confidence)
    
    return recognized_text, confidence_scores

def main():
    # Ti√™u ƒë·ªÅ
    st.title("üî§ Nh·∫≠n D·∫°ng K√Ω T·ª± Vi·∫øt Tay")
    st.markdown("Upload ·∫£nh ch·ª©a k√Ω t·ª± vi·∫øt tay ƒë·ªÉ nh·∫≠n d·∫°ng th√†nh text")
    
    # Load model
    model = load_ocr_model()
    
    if model is None:
        st.error("Kh√¥ng th·ªÉ load model. Vui l√≤ng ki·ªÉm tra file 'model.h5'")
        st.stop()
    
    # Sidebar cho c√†i ƒë·∫∑t
    st.sidebar.header("C√†i ƒë·∫∑t")
    show_processed = st.sidebar.checkbox("Hi·ªÉn th·ªã ·∫£nh ƒë√£ x·ª≠ l√Ω", value=True)
    show_confidence = st.sidebar.checkbox("Hi·ªÉn th·ªã ƒë·ªô tin c·∫≠y", value=True)
    
    # File uploader
    uploaded_file = st.file_uploader(
        "Ch·ªçn ·∫£nh ch·ª©a k√Ω t·ª± vi·∫øt tay",
        type=['png', 'jpg', 'jpeg', 'bmp'],
        help="H·ªó tr·ª£ c√°c ƒë·ªãnh d·∫°ng: PNG, JPG, JPEG, BMP"
    )
    
    if uploaded_file is not None:
        # ƒê·ªçc ·∫£nh
        image = Image.open(uploaded_file)
        img_array = np.array(image)
        
        # Hi·ªÉn th·ªã ·∫£nh g·ªëc
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("·∫¢nh g·ªëc")
            st.image(image, caption="·∫¢nh ƒë√£ upload", use_column_width=True)
        
        # X·ª≠ l√Ω nh·∫≠n d·∫°ng
        with st.spinner("ƒêang x·ª≠ l√Ω nh·∫≠n d·∫°ng..."):
            try:
                # Ph√¢n ƒëo·∫°n k√Ω t·ª±
                char_images, bounding_boxes = segment_characters(img_array)
                
                if len(char_images) == 0:
                    st.warning("Kh√¥ng t√¨m th·∫•y k√Ω t·ª± n√†o trong ·∫£nh. H√£y th·ª≠ v·ªõi ·∫£nh kh√°c.")
                else:
                    # Nh·∫≠n d·∫°ng text
                    recognized_text, confidence_scores = recognize_text(model, char_images)
                    
                    with col2:
                        st.subheader("K·∫øt qu·∫£ nh·∫≠n d·∫°ng")
                        
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£
                        st.success(f"**Text nh·∫≠n d·∫°ng:** {recognized_text}")
                        
                        if show_confidence and confidence_scores:
                            avg_confidence = np.mean(confidence_scores)
                            st.info(f"**ƒê·ªô tin c·∫≠y trung b√¨nh:** {avg_confidence:.2%}")
                    
                    # Hi·ªÉn th·ªã k√Ω t·ª± ƒë√£ ph√¢n ƒëo·∫°n
                    if show_processed and char_images:
                        st.subheader("K√Ω t·ª± ƒë√£ ph√¢n ƒëo·∫°n")
                        
                        # T·∫°o grid hi·ªÉn th·ªã k√Ω t·ª±
                        cols = st.columns(min(len(char_images), 6))
                        for i, (char_img, confidence) in enumerate(zip(char_images, confidence_scores)):
                            with cols[i % 6]:
                                st.image(
                                    char_img, 
                                    caption=f"{recognized_text[i]} ({confidence:.1%})",
                                    width=80
                                )
                    
                    # Th·ªëng k√™ chi ti·∫øt
                    with st.expander("Chi ti·∫øt nh·∫≠n d·∫°ng"):
                        st.write(f"**S·ªë k√Ω t·ª± t√¨m th·∫•y:** {len(char_images)}")
                        st.write(f"**Text nh·∫≠n d·∫°ng:** {recognized_text}")
                        
                        if confidence_scores:
                            for i, (char, conf) in enumerate(zip(recognized_text, confidence_scores)):
                                st.write(f"K√Ω t·ª± {i+1}: **{char}** - ƒê·ªô tin c·∫≠y: {conf:.2%}")
                
            except Exception as e:
                st.error(f"C√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω ·∫£nh: {str(e)}")
    
    # H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng
    with st.expander("H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng"):
        st.markdown("""
        ### C√°ch s·ª≠ d·ª•ng:
        1. **Upload ·∫£nh:** Ch·ªçn file ·∫£nh ch·ª©a k√Ω t·ª± vi·∫øt tay (PNG, JPG, JPEG, BMP)
        2. **Ch·ªù x·ª≠ l√Ω:** H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông ph√¢n ƒëo·∫°n v√† nh·∫≠n d·∫°ng k√Ω t·ª±
        3. **Xem k·∫øt qu·∫£:** Text ƒë∆∞·ª£c nh·∫≠n d·∫°ng s·∫Ω hi·ªÉn th·ªã c√πng v·ªõi ƒë·ªô tin c·∫≠y
        
        ### L∆∞u √Ω:
        - ·∫¢nh n√™n c√≥ n·ªÅn s√°ng, ch·ªØ t·ªëi ƒë·ªÉ k·∫øt qu·∫£ t·ªët nh·∫•t
        - K√Ω t·ª± vi·∫øt r√µ r√†ng, kh√¥ng qu√° nh·ªè
        - Hi·ªán t·∫°i ch·ªâ h·ªó tr·ª£ nh·∫≠n d·∫°ng ch·ªØ c√°i ti·∫øng Anh (A-Z)
        - Model ƒë∆∞·ª£c train tr√™n dataset EMNIST
        """)

if __name__ == "__main__":
    main()